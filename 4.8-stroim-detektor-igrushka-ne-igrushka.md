# Подглава 4.8 Строим детектор игрушка/не игрушка

В следующем разделе описана программа обучения для нашей сверточной нейронной сети \(CNN\), которая расскажет о игрушках отдельно от не игрушек, то есть она расскажет нам, есть ли игрушка в поле зрения камеры.

Мы начинаем с создания наших обучающих наборов. Мы разделяем наши фотографии игровой комнаты на фотографии с игрушками и фотографии без игрушек. Мы помещаем игрушки в директорию в каталоге нашей программы под названием _images/toys_. Мы помещаем изображения без игрушек в каталог с именем _images/not\_toys_. Нам нужно около 200 примеров каждого. Все идет нормально:

![](.gitbook/assets/image%20%2815%29.png)

Примеры изображений без игрушек на них \(верхнее изображение\) и с игрушками на них \(нижнее изображение\). Спасибо внукам за помощь в предоставлении этих примеров. Мы можем увидеть разницу, но может ли робот?

Теперь мы можем начать нашу программу обучения нашей нейронной сети, о которой мы так много слышали. Мы будем использовать сверточную нейронную сеть \(CNN\) с фреймворком Keras. Keras \(слово, по-гречески означающее «Рог» и имеющее сложную предысторию, которую вы сможете посмотреть самостоятельно\) – это упрощенный интерфейс для нескольких пакетов нейронных сетей, таких как TensorFlow \(то, что я использую\), CNTK, или Theano. Keras делает нашу работу намного проще, что является благом, учитывая, насколько сложной может быть теория нейронных сетей. У меня есть хорошие новости – практика нейронной сети намного проще теории.

Этот раздел был вдохновлен работой Адриана Росброка на великолепном веб-сайте PyimageSearch \([https://www.pyimagesearch.com/](https://www.pyimagesearch.com/)\) и «Приключениях в машинном обучении» Энди Томаса \([https://adventuresinmachinelearning.com](https://adventuresinmachinelearning.com)\). Архитектура LeNet основана на градиентном методе обучении, применяемом к распознаванию документов, написанном в 1998 году Янном ЛеКуном, Леоном Бутту, Йошуа Бенжио и Патриком Хаффнером.

Совет: вы можете контролировать, используете ли вы CUDA, библиотеку нейронной сети Nvidia GPU, для ускорения вашей программы. Переменная среды CUDA\_VISIBLE\_DEVICES включает или выключает CUDA. Установите для этой переменной среды значение -1, чтобы отключить CUDA, в противном случае используйте 0 \(ноль\).

Давайте поскорее начнем. Откройте редактор и создайте программу с названием _trainTheCNN.py_.

Как обычно для программы на Python, мы начинаем с импорта нескольких библиотек:

```text
код на pyhon
# program to train Convolution Neural Network to detect toys and not toys
# import the necessary packages
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam, SGD,Adadelta,Adagrad
from sklearn.model_selection import train_test_split
from keras.preprocessing.image import img_to_array
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.layers.core import Activation
from keras.layers.core import Flatten
from keras.layers.core import Dense
from keras import backend as K
from imutils import paths
import numpy as np
import random
import cv2
import os, time
```

Вы заметите, что большая часть этих импортов, как и ожидалось, из Keras. Мы будем использовать _**ImageDataGenerator**_ для увеличения нашего изображения волшебным образом, чтобы они предоставляли больше обучающих данных, тестировали некоторые оптимизаторы обучения, называемые Adam, тип стохастического градиентного спуска, который использует адаптивные скорости обучения, несколько процедур обработки изображений и несколько уровней из Keras.

Теперь мы создаем класс для построения нашей нейронной сети, который мы будем использовать позже в программе. Это забавная часть, потому что мы можем убрать это с пути. Мы собираемся создать общий объектный класс LeNet. Входными параметрами являются ширина, высота и глубина наших изображений \(которые составляют 126 x 126 пикселей с глубиной трех цветов\). У нас есть два класса, которые мы будем искать: _toys_ и _not\_toys_. Мы используем последовательный тип нейронной сети, который охватывает большинство нейронных сетей. Keras также позволяет вам определять свою собственную архитектуру модели, но мы не будем вдаваться в подробности. Для начала мы установим форму и размер нашей модели:

```text
class LeNet:
@staticmethod
def build(width, height, depth, classes):
# initialize the model
model = Sequential()
inputShape = (height, width, depth)
```

Некоторые файлы данных сначала идут по _channels first_, поэтому в этом случае мы устанавливаем форму 3 x высота x ширина вместо высота x ширина x 3. Три канала – это значения красного, зеленого и синего цветов:

```text
# if we are using "channels first", update the input shape
if K.image_data_format() == "channels_first":
inputShape = (depth, height, width)
```

Теперь мы добавляем наш первый уровень в модель. Это слой свёртки с 20 свёртками \(операциями\), каждая из которых выделит некоторую особенность изображения. Мы устанавливаем размер свёртки равным 5 x 5 и добавляем к изображению отступы. Наша функция активации – это ReLU, которая является значением, если значение больше нуля, и 0 в противном случае. Она «исправляет» любое значение меньше нуля просто нулем. Помните, что цвет меньше нуля – просто черный, наши значения цвета будут иметь значения от 0 до 1. Поскольку значение цвета меньше нуля не имеет смысла – чернее черного? – мы просто делаем его равным нулю.

```text
model.add(Conv2D(20, (5, 5), padding="same", input_shape=inputShape))
model.add(Activation("relu"))
```

Наш второй уровень – это уровень максимального пула. Мы используем ячейки 2 x 2 \(4 пикселя\) и пропускаем \(перешагиваем\) 2 пикселя во избежание дублирования. Это уменьшает размер нашего изображения на 1⁄4 \(половина ширины и половина высоты = одна четверть\). Теперь вместо 128 x 128 мы получаем 64 x 64 пикселя:

```text
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
```

Теперь мы добавляем еще один уровень свёртки, который вдвое сложнее первого – 40 свёрток вместо 20. Это обычная практика в свёрточной нейронной сети \(CNN\). Этот уровень обнаруживает больше деталей, чем первый уровень. Если можно сказать, что первый уровень обнаруживает глаза и пальцы, второй уровень обнаруживает руки и ноги. Мы используем ту же функцию ReLU, что и раньше, по той же причине. Активация определяет выход нейронов из этого уровня:

```text
model.add(Conv2D(40, (5, 5), padding="same")) model.add(Activation("relu"))
```

Теперь мы добавляем еще один уровень максимального пула, как и прежде. Наши 64 x 64 пикселя теперь 32 x 32. Мы видим только самые большие особенности изображений после этого:

```text
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
```

Теперь мы сглаживаем изображение при подготовке использования классификатора позже. Мы превращаем наше изображение размером 64 x 64 x 3 в одномерный массив с 12,228 значениями:

```text
model.add(Flatten())
```

После функции сглаживания мы добавляем плотный \(плотно связанный\) уровень – каждый нейрон соединяется с каждым нейроном в уровне ниже. Его функция активации также по-прежнему ReLU:

```text
model.add(Dense(500))
model.add(Activation("relu"))
```

Наш последний уровень имеет только два класса для хранения наших выходных значений. Один – это вероятность от 0 до 1, что наше изображение содержит игрушку, а другой – вероятность того, что изображение не содержит игрушку. Классификатор softmax берет выходные данных из сети и нормализует их в значения – одно на класс, которые сводятся к одному. Softmax – более общая функция, которая может обрабатывать несколько классов. Мы используем только два, но это делает сеть более общей:

```text
# softmax classifier
model.add(Dense(classes))
model.add(Activation("softmax"))

# return the completed network structure
return model
```

Итак, LeNet – это простая структура CNN с двумя уровнями свертки.

Теперь мы обозначим некоторые из наших файлов данных, в том числе, где находятся наши обучающие изображения:

```text
# data files
imageDirectory = "images/"
model_file = "toy_not_toy.model"
```

Вот метапараметры для нашей программы обучения. Мы устанавливаем количество повторений, на которых следует обучать сеть, скорость обучения \(как быстро можно изменять значения весов\) и размер пакета. Размер пакета – это количество изображений, которые мы храним в памяти одновременно. Если у нас заканчивается память, мы можем уменьшить размер пакета:

```text
# Set up the number of training passes (epochs), learning rate, and batch size
EPOCHS = 200
LEARNING_RATE = 1e-3
BATCH_SIZE = 32
```

В этом разделе настраиваются обучающие изображения и метки, чтобы мы могли их использовать:

```text
# initialize the data and labels
print("Loading training images set...")
data = [ ]
labels = [ ]
```

Мы загружаем изображения с жесткого диска и перемешиваем их случайным образом, поэтому нет определенного порядка, который сеть могла бы случайно узнать:

```text
# grab the images from the directories and randomly shuffle them
imagePaths = sorted(list(paths.list_images(imageDirectory)))

# use a random seed number from the time clock
random.seed(int(time.time()%1000))
random.shuffle(imagePaths)
```

Мы загружаем все изображения по одному, уменьшаем их до 128 x 128 пикселей и добавляем их в массив чисел. Мы помещаем это в массив с названием _data_:

```text
# loop over the input images
for imagePath in imagePaths:

# load the image, pre-process it, and store it in the data list
image = cv2.imread(imagePath)
image = cv2.resize(image, (128, 128))
image = img_to_array(image)
data.append(image)
```

Для создания списка меток мы поместили картинки с игрушками в один каталог, а изображения без игрушек – в другой. Мы используем имя каталога в качестве метки для изображения \(_toy_ или _not\_toy_\). Мы помещаем это в массив с именем _labels_, где мы сможем позже снова их найти:

```text
# extract the class label from the image path and update the labels list
label = imagePath.split(os.path.sep)[-2]
if label == "toy":
label = 1
else:
label = 0
labels.append(label)
```

Теперь мы преобразуем значения цветов в нашем изображении из целых чисел \(integer\) от 0 до 255 в действительные числа \(real\) от 0 до 1. Это называется нормализацией и является стандартным шагом в нейронных сетях для получения всех входов в общем диапазоне:

```text
# Normalize the values of the pixels to be between 0 and 1 instead of 0 to 255
data = np.array(data, dtype="float") / 255.0
labels = np.array(labels)
```

Поскольку мы обучаем нашу нейронную сеть, нам необходимо постоянно проверять, работает ли сеть должным образом. Процесс обучения сообщает нам об ошибках в изображениях, которые использовались в обучающем наборе, но мы будем использовать эту сеть для классификации новых изображений, которые он никогда не видел прежде. Мы разделили нашу поставку изображений на две группы: обучающий набор, который имеет большинство \(80%\) изображений, и тестовый набор, в котором оставшиеся 20%. Мы обучаем сеть с большим набором изображений, и затем проводим тестирование по меньшему набору изображений, но которые не были частью обучающего набора. Это дает нам основание полагать, что сеть будет правильно классифицировать изображения, которые она не видела ранее:

```text
# split the data between a testing set and a training set
(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.20, random_state=time.time())
```

Теперь мы конвертируем метки из текста \(_toy_ или _not\_toy_\) в числа – 0 и 1, чтобы сеть могла их обработать:

```text
# convert the labels from integers to vectors
trainY = to_categorical(trainY, num_classes=2)
testY = to_categorical(testY, num_classes=2)
```

Это одна из забавных частей. Мы собираемся расширить наши данные путем случайного смещения, сдвига, масштабирования и переворачивания изображений, чтобы одно изображение стало 10. Это дает нашей сети гораздо больше информации для работы:

```text
# construct the image generator for data augmentation
aug = ImageDataGenerator(rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.1, zoom_range=0.2, horizontal_flip=True, fill_mode="nearest")
```

Теперь мы готовы построить нашу сеть. Мы создаем экземпляр объекта LeNet, используя функцию _build_ для создания нашей структуры данных _cnNetwork_ \(CNN Network\). Мы уже рассмотрели, что она делает – две свертки, сглаживание и выходной уровень. Мы устанавливаем размер нашей сети на 124 x 124 пикселя, устанавливаем нашу глубину на три для цветного изображения, а затем устанавливаем классы на 2 – игрушка и не игрушка. На следующем шаге настраивается наш оптимизатор обучения. Я выбрал ADAM, который описан как _generic go-to_ оптимизатор для CNN. ADAM имеет модель стохастического градиентного спуска, которая является быстрой, а также множество модификаций улучшают кривую обучения и корректируют скорость обучения по мере обучения модели. Модель замедляет скорость обучения, когда сеть достигает максимального уровня и градиент выравнивается. Я включил код обычного SGD для вас на случай, если вы захотите сравнить их, как я делал при построении модели. ADAM работал немного лучше. Если бы я использовал оптимизатор SGD, мне бы пришлось добавить больше обучающих проходов \(периодов\):

```text
# initialize the weights of the network
print("Building CNN network...")
cnNetwork = LeNet.build(width=124, height=124, depth=3, classes=2)

#use adam optimizer. tried SGD for comparison - needs more epochs (>100)
opt = Adam(lr=LEARNING_RATE, decay=LEARNING_RATE / EPOCHS)
#opt = SGD(lr=LEARNING_RATE,decay=LEARNING_RATE / EPOCHS)
```

Мы компилируем сеть и указываем, какой будет наша функция потерь. Мы используем энтропию _binary\_cross_, которая подходит для сети, имеющей только два класса. Если классов более двух, вы можете использовать категориальную перекрестную энтропию. Системы кросс-энтропийной потери используются для сетей, где конечный результат представляет собой число вероятности от 0 до 1, например, ту, которую мы строим. Кросс-энтропийная потеря – это логарифмическая потеря, где ошибка значительно возрастает по мере того, как ожидаемый результат и прогноз сети расходятся. Это преувеличение помогает вернуть сеть к цели обучения. Как правило, кросс-энтропийная потеря является отрицательным логарифмом \( $$-log$$ \) разницы между истинным результатом \(метка на изображении\) и выходом сети \(который является числом вероятности от 0 до 1\):

```text
cnNetwork.compile(loss="binary_crossentropy", optimizer=opt, metrics=["accuracy"])
```

Этот блок кода фактически обучает сеть. Мы можем думать о создании нейронной сети как о ступенчатом приближении нелинейной функции, которую математики любят называть _**подгонкой кривой**_ – созданием функции кривой, которая соответствует входным данным. Следовательно, функция, которая обучает сеть, называется _**функцией приспособленности**_. Мы вводим наши обучающие наборы \(_trainX_ = _toys_ и _trainY_ = _not toys_\), размер пакета \(который регулирует объем используемой памяти\), наши данные проверки, с которыми мы будем тестировать, и количество периодов.

```text
# train the network - here is where the magic happens...
print("[INFO] training network...")
H = cnNetwork.fit_generator(aug.flow(trainX, trainY, batch_size=BATCH_SIZE), validation_data=(testX, testY), steps_per_epoch=len(trainX) // BATCH_SIZE, epochs=EPOCHS, verbose=1)
```

Программа выведет отчеты о состоянии обучения. Если вы можете собрать эти данные и сделать из них график, как я сделал ниже. Вывод выглядит следующим образом – вы можете видеть время, которое занимает каждый период – в данном случае это около девяти секунд. О потере или ошибке сообщается, и вы можете видеть, что со временем она уменьшается. Acc ставит точность обученной модели, и затем сообщается об ошибке и точности проверки:

{% tabs %}
{% tab title="Output" %}
3/3 \[==============================\] - 11s 4s/step - loss: 0.8696 - acc:

0.6264 - val\_loss: 0.6710 - val\_acc: 0.5806

Epoch 2/100

3/3 \[==============================\] - 10s 3s/step - loss: 0.6962 - acc:

0.5000 - val\_loss: 0.7323 - val\_acc: 0.2903

Epoch 3/100

3/3 \[==============================\] - 9s 3s/step - loss: 0.6913 - acc:

0.5818 - val\_loss: 0.6469 - val\_acc: 0.7097

Epoch 4/100

3/3 \[==============================\] - 9s 3s/step - loss: 0.7441 - acc:

0.6458 - val\_loss: 0.6768 - val\_acc: 0.7097

Epoch 5/100

3/3 \[==============================\] - 9s 3s/step - loss: 0.7307 - acc:

0.6169 - val\_loss: 0.6315 - val\_acc: 0.7097

Epoch 6/100

3/3 \[==============================\] - 9s 3s/step - loss: 0.6108 - acc:

0.7500 - val\_loss: 0.6369 - val\_acc: 0.7097

Epoch 7/100

3/3 \[==============================\] - 9s 3s/step - loss: 0.6635 - acc:

0.6530 - val\_loss: 0.6354 - val\_acc: 0.7097

Epoch 8/100

3/3 \[==============================\] - 9s 3s/step - loss: 0.6594 - acc:

0.6474 - val\_loss: 0.6193 - val\_acc: 0.7097

Epoch 9/100

3/3 \[==============================\] - 9s 3s/step - loss: 0.6551 - acc:

0.6458 - val\_loss: 0.6085 - val\_acc: 0.7097
{% endtab %}
{% endtabs %}

Если вы соберете все эти данные и составите график, он будет выглядеть так:

![](.gitbook/assets/image%20%283%29.png)

Это результат, полученный мной при обучении сети с более 200 периодами, 100 изображениями с игрушками и 100 изображениями без игрушек. На самом деле этого мало для CNN, 200 изображений было бы лучше, поэтому я сделаю еще несколько снимков. Несмотря на это, выходные результаты довольно хорошие – мы имеем точность распознания игрушки/не игрушки в диапазоне 90%, что более чем достаточно для нашего робота. Мы также можем посмотреть на кривые потерь обучения и валидации – потери обучения продолжают уменьшаться после того, как точность выровнялась. Это означает, что значения ошибок и веса все еще могут быть улучшены после того, как точность была увеличена. Это дает сети больше уверенности. Мы можем реально остановить обучение примерно через 150 периодов.

Нашим последним шагом является сохранение сетевых весов и смещений в файле, чтобы мы могли использовать их в нашем следующем разделе, который представляет собой программу для проверки правильности работы нашей нейронной сети:

```text
# save the CNN network weights to file
print("Saving Network Weights to file...")
cnNetwork.save(model_file)
```



